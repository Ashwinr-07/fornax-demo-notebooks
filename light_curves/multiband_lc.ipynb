{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiwavelength light curves using archival data\n",
    "\n",
    "### Summary:\n",
    " - model plots after van Velzen et al. 2021, https://arxiv.org/pdf/2111.09391.pdf\n",
    " \n",
    "### Input:\n",
    " - a catalog of CLAGN from the literature\n",
    "\n",
    "### Output:\n",
    " - an archival optical + IR + neutrino light curve\n",
    " \n",
    "### Technical Goals:\n",
    " - should be able to run from a clean checkout from github\n",
    " - should be able to automatically download all catalogs & images used\n",
    " - need to have all photometry in the same physical unit\n",
    " - need to have a data structure that is easy to use but holds light curve information (time and units) and is extendable to ML applications\n",
    " - need to have a curated list of catalogs to search for photometry that is generalizeable to other input catalogs\n",
    " \n",
    "### Authors:\n",
    "IPAC SP team\n",
    "\n",
    "### Acknowledgements:\n",
    "Suvi Gezari, Antara Basu-zych,\n",
    "MAST, HEASARC, & IRSA Fornax teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightkurve in /opt/conda/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: patsy>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (0.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (1.0.2)\n",
      "Requirement already satisfied: fbpca>=1.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (1.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (4.10.0)\n",
      "Requirement already satisfied: memoization>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (0.4.0)\n",
      "Requirement already satisfied: oktopus>=0.1.2 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.25.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (4.50.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (2.24.0)\n",
      "Requirement already satisfied: astropy>=5.0 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (5.0.1)\n",
      "Requirement already satisfied: astroquery>=0.3.10 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (0.4.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (1.3.5)\n",
      "Requirement already satisfied: uncertainties>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (3.1.7)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (1.8.0)\n",
      "Requirement already satisfied: urllib3>=1.23 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (1.25.11)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (1.21.5)\n",
      "Requirement already satisfied: bokeh>=1.1 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (2.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.1 in /opt/conda/lib/python3.8/site-packages (from lightkurve) (3.5.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /opt/conda/lib/python3.8/site-packages (from astropy>=5.0->lightkurve) (6.0)\n",
      "Requirement already satisfied: packaging>=19.0 in /opt/conda/lib/python3.8/site-packages (from astropy>=5.0->lightkurve) (20.4)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /opt/conda/lib/python3.8/site-packages (from astropy>=5.0->lightkurve) (2.0.0.1)\n",
      "Requirement already satisfied: html5lib>=0.999 in /opt/conda/lib/python3.8/site-packages (from astroquery>=0.3.10->lightkurve) (1.1)\n",
      "Requirement already satisfied: keyring>=4.0 in /opt/conda/lib/python3.8/site-packages (from astroquery>=0.3.10->lightkurve) (22.3.0)\n",
      "Requirement already satisfied: pyvo>=1.1 in /opt/conda/lib/python3.8/site-packages (from astroquery>=0.3.10->lightkurve) (1.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4>=4.6.0->lightkurve) (2.3.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.8/site-packages (from bokeh>=1.1->lightkurve) (2.11.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.8/site-packages (from bokeh>=1.1->lightkurve) (9.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.8/site-packages (from bokeh>=1.1->lightkurve) (6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/lib/python3.8/site-packages (from bokeh>=1.1->lightkurve) (4.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1->lightkurve) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1->lightkurve) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1->lightkurve) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1->lightkurve) (4.29.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1->lightkurve) (2.8.1)\n",
      "Requirement already satisfied: autograd in /opt/conda/lib/python3.8/site-packages (from oktopus>=0.1.2->lightkurve) (1.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.4->lightkurve) (2021.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from patsy>=0.5.0->lightkurve) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->lightkurve) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->lightkurve) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->lightkurve) (2.10)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.0->lightkurve) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.0->lightkurve) (3.1.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from uncertainties>=3.1.4->lightkurve) (0.18.2)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from html5lib>=0.999->astroquery>=0.3.10->lightkurve) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=2.9->bokeh>=1.1->lightkurve) (1.1.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.8/site-packages (from keyring>=4.0->astroquery>=0.3.10->lightkurve) (3.3.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.8/site-packages (from keyring>=4.0->astroquery>=0.3.10->lightkurve) (0.7.1)\n",
      "Requirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.8/site-packages (from SecretStorage>=3.2->keyring>=4.0->astroquery>=0.3.10->lightkurve) (3.1.1)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.8/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery>=0.3.10->lightkurve) (1.14.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery>=0.3.10->lightkurve) (2.20)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ztfquery in /opt/conda/lib/python3.8/site-packages (1.19.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import axs\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from astroquery.ipac.ned import Ned\n",
    "from astroquery.heasarc import Heasarc\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, vstack, hstack, unique\n",
    "from astropy.io import ascii\n",
    "\n",
    "\n",
    "try: # Python 3.x\n",
    "    from urllib.parse import quote as urlencode\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2.x\n",
    "    from urllib import pathname2url as urlencode\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "try: # Python 3.x\n",
    "    import http.client as httplib \n",
    "except ImportError:  # Python 2.x\n",
    "    import httplib   \n",
    "\n",
    "!pip install lightkurve --upgrade\n",
    "import lightkurve as lk\n",
    "\n",
    "!pip install ztfquery\n",
    "from ztfquery import lightcurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following paper to make a sample of CLAGN: https://iopscience.iop.org/article/10.3847/1538-4357/aaca3a \n",
    "\n",
    "# This sample can later be switched out to a differen/larger sample of \"interesting\" targets\n",
    "\n",
    "#use ADS to find the refcode for this paper\n",
    "CLAGN = Ned.query_refcode('2018ApJ...862..109Y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the best data structure for this work?\n",
    " - list of requirements is being kept here: https://github.com/fornax-navo/fornax-demo-notebooks/issues/69 \n",
    " - some things to keep an eye on as other people are actively working on this field\n",
    "     - astropy has a light curve class\n",
    "         -would require development work to make this work for multiwavelength application\n",
    "     - LINCC people are interested in this and might have some suggestions on a 6mo. timescale\n",
    "     - xarray\n",
    "     - pandas pint has units support but also has a warning that it doesn't yet work perfectly\n",
    "     - lightKurve is not suitable for this application\n",
    "     - sunpy is also not suitable for this application\n",
    "\n",
    "### Since there is nothing perfectly ready now, we need to go with something practical for the time being\n",
    " - instead of one large dataframe with the multiwavelength information, we could keep them as seperate astropy light curves for each band, do the feature extraction on each light curve and keep the features in one large dataframe. - how would we link targets between bands?\n",
    " - ZTF keeps the light curve info as multidimensional arrays in pandas columns - this works out of the box but doesn't have unit support so we just need to do that manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "astropy.table.table.Table"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(CLAGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build a list of skycoords from target ra and dec #####\n",
    "coords_list = [\n",
    "    SkyCoord(ra, dec, frame='icrs', unit='deg')\n",
    "    for ra, dec in zip(CLAGN['RA'], CLAGN['DEC'])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (0.28136, -0.09789)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (21.70037, -8.66335)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (29.99, 0.55301)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (29.99015, 0.55288)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (120.94815, 42.97747)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (127.88438, 36.77146)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (132.49077, 27.79139)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (137.38346, 47.79186)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (144.37635, 26.04226)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (144.39777, 32.5472)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (150.84777, 35.41774)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (152.97077, 54.7018)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (166.09674, 63.71816)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (166.22989, 1.31573)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (167.60602, -0.05948)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (168.90238, 5.74715)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (169.62351, 32.06666)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (173.12142, 3.95808)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (177.66385, 36.54956)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (178.11465, 32.16646)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (194.81978, 55.25199)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (199.87808, 67.89872)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (209.07707, -1.2539)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (209.73263, 49.5706)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (221.97599, 28.55669)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (233.48331, 1.17494)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (236.3735, 25.19107)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (237.57179, 41.65064)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (238.24292, 27.62456)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (238.66774, 36.4978)>,\n",
       " <SkyCoord (ICRS): (ra, dec) in deg\n",
       "     (354.01242, 0.29132)>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find light curves for these targets in NASA catalogs\n",
    "- look at NAVO use cases to get help with tools to do this - although they mostly use pyvo\n",
    "- deciding up front to use astroquery instead of pyvo\n",
    "    - astroquery is apparently more user friendly\n",
    "- data access concerns:\n",
    "    - can't ask the archives to search their entire holdings\n",
    "        - not good enough meta data\n",
    "        - not clear that the data is all vetted and good enough to include for science\n",
    "        - all catalogs have differently named columns so how would we know which columns to keep\n",
    "    - instead work with a curated list of catalogs for each archive\n",
    "        - focus on general surveys\n",
    "        - try to ensure that this list is also appropriate for a generalization of this use case to other input catalogs\n",
    "        - could astroquery.NED be useful in finding a generalized curated list\n",
    "- How do we know we have a match that is good enough to include in our light curve\n",
    "     - look at nway for the high energy catalogs\n",
    "     - probably need to generate a table of search radii for each catalog based on bandpass\n",
    "         - need domain knowledge for that\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 HEASARC: FERMI & Beppo SAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n",
      "no results at that location for  FERMIGTRIG\n",
      "no results at that location for  SAXGRBMGRB\n"
     ]
    }
   ],
   "source": [
    "mission_list = ['FERMIGTRIG', 'SAXGRBMGRB']\n",
    "radius = 0.1*u.degree\n",
    "\n",
    "for ccount, coord in enumerate(coords_list):\n",
    "    #use astroquery to search that position for either a Fermi or Beppo Sax trigger\n",
    "    for mcount, mission in enumerate(mission_list):\n",
    "        try:\n",
    "            results = heasarc.query_region(coord, mission = mission, radius = radius)#, sortvar = 'SEARCH_OFFSET_')\n",
    "            print (\"got a live one\")\n",
    "            #need to figure out what this result would look like and how to add that to the saved data structure\n",
    "        except AttributeError:\n",
    "            print(\"no results at that location for \", mission)\n",
    "\n",
    "\n",
    "#**** These HEASARC searches are returning an attribute error because of an astroquery bug\n",
    "# bug submitted to astroquery Oct 18, waiting for a fix.\n",
    "# if that gets fixed, can probably change this cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 IRSA: ZTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 404\n",
      "1 429\n",
      "2 612\n",
      "3 612\n",
      "4 387\n",
      "5 1109\n",
      "6 1202\n",
      "7 162\n",
      "8 791\n",
      "9 525\n",
      "10 888\n",
      "11 2346\n",
      "12 931\n",
      "13 183\n",
      "14 347\n",
      "15 423\n",
      "16 1029\n",
      "17 397\n",
      "18 1094\n",
      "19 1088\n",
      "20 1300\n",
      "21 1359\n",
      "22 407\n",
      "23 33\n",
      "24 1901\n",
      "25 644\n",
      "26 1010\n",
      "27 2295\n",
      "28 883\n",
      "29 2024\n",
      "30 438\n"
     ]
    }
   ],
   "source": [
    "#python package ztfquery is not a good solution for this because it requires IRSA password\n",
    "#Instead will construct the URL for an API query\n",
    "#https://irsa.ipac.caltech.edu/docs/program_interface/ztf_lightcurve_api.html\n",
    "ztf_radius = 0.000278   #as suggested by Dave Shupe\n",
    "\n",
    "for count, coord in enumerate(coords_list):\n",
    "    #doesn't take SkyCoord\n",
    "    ra = CLAGN['RA'][count]\n",
    "    dec = CLAGN['DEC'][count]\n",
    "    \n",
    "    #make the string for the URL query\n",
    "    #ask for all three bands (g, r, i)\n",
    "    #don't want data that is flagged as unusable by the ZTF pipeline\n",
    "    urlstr = 'https://irsa.ipac.caltech.edu/cgi-bin/ZTF/nph_light_curves?POS=CIRCLE %f %f %f&BANDNAME=g,r,i&FORMAT=ipac_table&BAD_CATFLAGS_MASK=32768'%(ra, dec,ztf_radius)\n",
    "\n",
    "    response = requests.get(urlstr)\n",
    "    if response.ok:\n",
    "        ztf_lc = ascii.read(response.text, format='ipac')\n",
    "        #print(count, len(ztf_lc))\n",
    "        #this could be up to 3 light curves because there are 3 filters\n",
    "        #need to sort by filtercode 'zg','zr','zi'\n",
    "        #and store the light curves\n",
    "    else:\n",
    "        print(count, \" There is no ZTF light curve at this position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 IRSA:WISE\n",
    "\n",
    "- Dave Shupe has made a catalog of neowise light curves of half the sky in a parquet file\n",
    "\n",
    "- Pandas is not a good option for working with this catalog because it is so large (2 billion rows?)\n",
    "\n",
    "- Instead we can use AXS to cross match the CLAGN sample with the neowise catalog to find those rows in neowise which correspond to the CLAGN sample. AXS is a part of spark. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 53min 48s, sys: 4h 16min 37s, total: 6h 10min 25s\n",
      "Wall time: 23min 46s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#could load the neowise light curves into pandas, but would need to severely\n",
    "# filter the catalog to get it to fit into memory.  Since these targets are all over the sky\n",
    "# it is not obvious how to filter the catalog\n",
    "\n",
    "#Here is one way it could work in Pandas if we had a way to filter significantly before matching\n",
    "#subset = pd.read_parquet('/stage/irsa-data-download10/parquet-work/NEOWISE-R/neowise_lc_half.parquet',\n",
    "#                    engine='pyarrow', \n",
    "#                    filters=[ ('ra', '<', 121) , ('ra', '>', 120) , \n",
    "#                            ('dec', '<', 68) , ('dec', '>', -9),\n",
    "#                            ('cw_w1mpro', '>', 15.0) ])\n",
    "#\n",
    "#len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start up SPARK\n",
    "os.environ['SPARK_CONF_DIR'] = '/home/jkrick/axs_store/conf_alt'\n",
    "\n",
    "def spark_start(work_dir, database_dir, warehouse_dir):\n",
    "    from pyspark.sql import SparkSession\n",
    "    import os\n",
    "    \n",
    "    spark = (\n",
    "            SparkSession.builder\n",
    "            .appName(\"spark trial\")\n",
    "            .config(\"spark.sql.warehouse.dir\", warehouse_dir)\n",
    "            .config('spark.master', \"local[20]\")\n",
    "            .config('spark.driver.memory', '64G') # 128\n",
    "            .config('spark.executor.memory', '30G')\n",
    "            .config('spark.local.dir', work_dir)\n",
    "            .config('spark.memory.offHeap.enabled', 'true')\n",
    "            .config('spark.memory.offHeap.size', '128G') # 256\n",
    "            .config(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "            .config(\"spark.driver.maxResultSize\", \"60G\")\n",
    "            .config(\"spark.driver.extraJavaOptions\", \n",
    "                    f\"-Dderby.system.home={database_dir}\")\n",
    "            .config(\"spark.sql.hive.metastore.sharedPrefixes\",\n",
    "                    \"org.apache.derby\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "                    )   \n",
    "\n",
    "    return spark\n",
    "\n",
    "spark_session = spark_start(\n",
    "    \"/stage/irsa-staff-jkrick/spark_work\",\n",
    "    \"/home/jkrick/axs_store\",\n",
    "    \"/stage/irsa-staff-jkrick/sp_axs_warehouse/warehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the one we want is not yet available, add it to the list\n",
    "catalog = axs.AxsCatalog(spark_session)\n",
    "catlist = catalog.list_table_names()\n",
    "\n",
    "if 'neowise_lc_half' not in catlist:\n",
    "    catalog.import_existing_table('neowise_lc_half', \n",
    "        '/stage/irsa-data-download10/parquet-work/NEOWISE-R/neowise_lc_half.parquet',\n",
    "        import_into_spark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lazy load in the catalog\n",
    "neowise_lc_half = catalog.load('neowise_lc_half')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now figure out how to get the CLAGN catalog into AXS\n",
    "#can't go direct from astropy table into AXS, so first to pandas\n",
    "\n",
    "if 'axs_clagn' not in catlist:\n",
    "\n",
    "    pd_CLAGN = CLAGN.to_pandas()\n",
    "\n",
    "    #then pandas to spark dataframe\n",
    "    sp_CLAGN = spark_session.createDataFrame(pd_CLAGN)\n",
    "\n",
    "    #ok, saving below can't handle capital \"RA\" and \"DEC\", so need to change that\n",
    "    #also can't handle column names with spaces in them so need to rename those as well.\n",
    "    sp_CLAGN2 = sp_CLAGN.withColumnRenamed(\"RA\",\"ra\").withColumnRenamed(\"DEC\",\"dec\").withColumnRenamed(\"Object Name\", \"Object_name\").withColumnRenamed(\"Redshift Flag\",\"redshift_flag\").withColumnRenamed(\"Magnitude and Filter\", \"magnitude_and_filter\").withColumnRenamed(\"Photometry Points\",\"photometry_points\").withColumnRenamed(\"Redshift Points\", \"redshift_points\").withColumnRenamed(\"Diameter Points\",\"diameter_points\")\n",
    "\n",
    "    #now save spark to AXS\n",
    "    catalog.save_axs_table(sp_CLAGN2, 'AXS_CLAGN', calculate_zone=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gaia_edr3', 'catwise_corrected', 'neowise_lc_half', 'axs_clagn']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just confirm that worked:\n",
    "catalog = axs.AxsCatalog(spark_session)\n",
    "catlist = catalog.list_table_names()\n",
    "catlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lazy load in the catalog\n",
    "axs_clagn = catalog.load('axs_clagn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to try the crossmatch\n",
    "\n",
    "neowise_CLAGN = neowise_lc_half.crossmatch(axs_clagn, 2*axs.Constants.ONE_ASEC, return_min = True, include_dist_col = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 ms, sys: 12 ms, total: 34.4 ms\n",
      "Wall time: 2min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#lazy evaluation means the cross match won't happen until this cell gets executed\n",
    "neowise_CLAGN.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "axs.axsframe.AxsFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(neowise_CLAGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n",
      "Wall time: 15.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now get it into a format that I can handle\n",
    "#this is taking a long time 45min? for 29 rows?\n",
    "\n",
    "#neowise_CLAGN.toPandas()\n",
    "\n",
    "#instead maybe try parquet?  csv doesn't work since there are arrays in the columns\n",
    "#neowise_CLAGN.write.parquet(\"neowise_CLAGN.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 529 ms, total: 2.17 s\n",
      "Wall time: 1h 58min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#instead try pulling the data into a pandas dataframe\n",
    "#is this faster? no 1h 58 min.\n",
    "#pd_neowise_CLAGN = pd.DataFrame.from_records(neowise_CLAGN.collect(), columns=neowise_CLAGN.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 MAST: Pan-STARRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps1cone(ra,dec,radius,table=\"mean\",release=\"dr1\",format=\"csv\",columns=None,\n",
    "           baseurl=\"https://catalogs.mast.stsci.edu/api/v0.1/panstarrs\", verbose=False,\n",
    "           **kw):\n",
    "    \"\"\"Do a cone search of the PS1 catalog\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ra (float): (degrees) J2000 Right Ascension\n",
    "    dec (float): (degrees) J2000 Declination\n",
    "    radius (float): (degrees) Search radius (<= 0.5 degrees)\n",
    "    table (string): mean, stack, or detection\n",
    "    release (string): dr1 or dr2\n",
    "    format: csv, votable, json\n",
    "    columns: list of column names to include (None means use defaults)\n",
    "    baseurl: base URL for the request\n",
    "    verbose: print info about request\n",
    "    **kw: other parameters (e.g., 'nDetections.min':2)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = kw.copy()\n",
    "    data['ra'] = ra\n",
    "    data['dec'] = dec\n",
    "    data['radius'] = radius\n",
    "    return ps1search(table=table,release=release,format=format,columns=columns,\n",
    "                    baseurl=baseurl, verbose=verbose, **data)\n",
    "\n",
    "\n",
    "def ps1search(table=\"mean\",release=\"dr1\",format=\"csv\",columns=None,\n",
    "           baseurl=\"https://catalogs.mast.stsci.edu/api/v0.1/panstarrs\", verbose=False,\n",
    "           **kw):\n",
    "    \"\"\"Do a general search of the PS1 catalog (possibly without ra/dec/radius)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table (string): mean, stack, or detection\n",
    "    release (string): dr1 or dr2\n",
    "    format: csv, votable, json\n",
    "    columns: list of column names to include (None means use defaults)\n",
    "    baseurl: base URL for the request\n",
    "    verbose: print info about request\n",
    "    **kw: other parameters (e.g., 'nDetections.min':2).  Note this is required!\n",
    "    \"\"\"\n",
    "    \n",
    "    data = kw.copy()\n",
    "    if not data:\n",
    "        raise ValueError(\"You must specify some parameters for search\")\n",
    "    checklegal(table,release)\n",
    "    if format not in (\"csv\",\"votable\",\"json\"):\n",
    "        raise ValueError(\"Bad value for format\")\n",
    "    url = f\"{baseurl}/{release}/{table}.{format}\"\n",
    "    if columns:\n",
    "        # check that column values are legal\n",
    "        # create a dictionary to speed this up\n",
    "        dcols = {}\n",
    "        for col in ps1metadata(table,release)['name']:\n",
    "            dcols[col.lower()] = 1\n",
    "        badcols = []\n",
    "        for col in columns:\n",
    "            if col.lower().strip() not in dcols:\n",
    "                badcols.append(col)\n",
    "        if badcols:\n",
    "            raise ValueError('Some columns not found in table: {}'.format(', '.join(badcols)))\n",
    "        # two different ways to specify a list of column values in the API\n",
    "        # data['columns'] = columns\n",
    "        data['columns'] = '[{}]'.format(','.join(columns))\n",
    "\n",
    "# either get or post works\n",
    "#    r = requests.post(url, data=data)\n",
    "    r = requests.get(url, params=data)\n",
    "\n",
    "    if verbose:\n",
    "        print(r.url)\n",
    "    r.raise_for_status()\n",
    "    if format == \"json\":\n",
    "        return r.json()\n",
    "    else:\n",
    "        return r.text\n",
    "\n",
    "\n",
    "def checklegal(table,release):\n",
    "    \"\"\"Checks if this combination of table and release is acceptable\n",
    "    \n",
    "    Raises a VelueError exception if there is problem\n",
    "    \"\"\"\n",
    "    \n",
    "    releaselist = (\"dr1\", \"dr2\")\n",
    "    if release not in (\"dr1\",\"dr2\"):\n",
    "        raise ValueError(\"Bad value for release (must be one of {})\".format(', '.join(releaselist)))\n",
    "    if release==\"dr1\":\n",
    "        tablelist = (\"mean\", \"stack\")\n",
    "    else:\n",
    "        tablelist = (\"mean\", \"stack\", \"detection\")\n",
    "    if table not in tablelist:\n",
    "        raise ValueError(\"Bad value for table (for {} must be one of {})\".format(release, \", \".join(tablelist)))\n",
    "\n",
    "\n",
    "def ps1metadata(table=\"mean\",release=\"dr1\",\n",
    "           baseurl=\"https://catalogs.mast.stsci.edu/api/v0.1/panstarrs\"):\n",
    "    \"\"\"Return metadata for the specified catalog and table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table (string): mean, stack, or detection\n",
    "    release (string): dr1 or dr2\n",
    "    baseurl: base URL for the request\n",
    "    \n",
    "    Returns an astropy table with columns name, type, description\n",
    "    \"\"\"\n",
    "    \n",
    "    checklegal(table,release)\n",
    "    url = f\"{baseurl}/{release}/{table}/metadata\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    v = r.json()\n",
    "    # convert to astropy table\n",
    "    tab = Table(rows=[(x['name'],x['type'],x['description']) for x in v],\n",
    "               names=('name','type','description'))\n",
    "    return tab\n",
    "\n",
    "\n",
    "def addfilter(dtab):\n",
    "    \"\"\"Add filter name as column in detection table by translating filterID\n",
    "    \n",
    "    This modifies the table in place.  If the 'filter' column already exists,\n",
    "    the table is returned unchanged.\n",
    "    \"\"\"\n",
    "    if 'filter' not in dtab.colnames:\n",
    "        # the filterID value goes from 1 to 5 for grizy\n",
    "        id2filter = np.array(list('grizy'))\n",
    "        dtab['filter'] = id2filter[(dtab['filterID']-1).data]\n",
    "    return dtab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try for panstarrs\n",
    "radius = 1.0/3600.0 # radius = 1 arcsec\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(1,(10,10))\n",
    "\n",
    "        \n",
    "#for all objects\n",
    "for count, coord in enumerate(coords_list):\n",
    "    #doesn't take SkyCoord\n",
    "    ra = CLAGN['RA'][count]\n",
    "    dec = CLAGN['DEC'][count]\n",
    "\n",
    "    #see if there is an object in panSTARRS at this location\n",
    "    results = ps1cone(ra,dec,radius,release='dr2')\n",
    "    tab = ascii.read(results)\n",
    "    \n",
    "    # improve the format\n",
    "    for filter in 'grizy':\n",
    "        col = filter+'MeanPSFMag'\n",
    "        tab[col].format = \".4f\"\n",
    "        tab[col][tab[col] == -999.0] = np.nan\n",
    "        \n",
    "    #in case there is more than one object within 1 arcsec, sort them by match distance\n",
    "    tab.sort('distance')\n",
    "    \n",
    "    #if there is an object at that location\n",
    "    if len(tab) > 0:   \n",
    "        #got a live one\n",
    "        #print( 'for object', count, 'there is ',len(tab), 'match in panSTARRS', tab['objID'])\n",
    "\n",
    "        #take the closest match as the best match\n",
    "        objid = tab['objID'][0]\n",
    "        \n",
    "        #setup to pull light curve info\n",
    "        dconstraints = {'objID': objid}\n",
    "        dcolumns = (\"\"\"objID,detectID,filterID,obsTime,ra,dec,psfFlux,psfFluxErr,psfMajorFWHM,psfMinorFWHM,\n",
    "                    psfQfPerfect,apFlux,apFluxErr,infoFlag,infoFlag2,infoFlag3\"\"\").split(',')\n",
    "        # strip blanks and weed out blank and commented-out values\n",
    "        dcolumns = [x.strip() for x in dcolumns]\n",
    "        dcolumns = [x for x in dcolumns if x and not x.startswith('#')]\n",
    "\n",
    "\n",
    "        #get the actual detections and light curve info for this target\n",
    "        dresults = ps1search(table='detection',release='dr2',columns=dcolumns,**dconstraints)\n",
    "        \n",
    "        #sometimes there isn't actually a light curve for the target???\n",
    "        try:\n",
    "            ascii.read(dresults)\n",
    "        except FileNotFoundError:\n",
    "            print(\"There is no light curve\")\n",
    "            #no need to store PanSTARRS data for this one\n",
    "        else:\n",
    "            #There is a light curve for this target\n",
    "            \n",
    "            #fix the column names to include filter names\n",
    "            dtab = addfilter(ascii.read(dresults))\n",
    "            dtab.sort('obsTime')\n",
    "\n",
    "            #not yet ready to store these, but here is the light curve\n",
    "            #mixed from all 5 bands\n",
    "            t = dtab['obsTime']\n",
    "            flux = dtab['psfFlux']\n",
    "\n",
    "            #plot light curves on same plot just to know they are there?\n",
    "            #not currently working\n",
    "            #xlim = np.array([t.min(),t.max()])\n",
    "            #xlim = xlim + np.array([-1,1])*0.02*(xlim[1]-xlim[0])\n",
    "            #for i, filter in enumerate(\"grizy\"):\n",
    "            #    plt.subplot(511+i)\n",
    "            #    w = np.where(dtab['filter']==filter)\n",
    "            #    plt.plot(t[w],flux[w],'-o')\n",
    "            #    plt.ylabel(filter+' [Jy]')\n",
    "            #    plt.xlim(xlim)\n",
    "            #    #plt.gca().invert_yaxis()\n",
    "            #    if i==0:\n",
    "            #        plt.title(objid)\n",
    "            #plt.xlabel('Time [MJD]')\n",
    "            #plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 MAST: ATLAS all-sky stellar reference catalog (g, r, i) < 19mag\n",
    " -  MAST has this catalog but it is not clear that it has the individual epoch photometry and it is only accessible with casjobs, not through python notebooks.  \n",
    "\n",
    " https://archive.stsci.edu/hlsp/atlas-refcat2#section-a737bc3e-2d56-4827-9ab4-838fbf8d67c1\n",
    " \n",
    " - if we really want to pursue this, we can put in a MAST helpdesk ticket to see if a) they do have the light curves, and b) they could switch the catalog to a searchable with python version.  There are some ways of accessing casjobs through python (<https://github.com/spacetelescope/notebooks/blob/master/notebooks/MAST/HSC/HCV_CASJOBS/HCV_casjobs_demo.ipynb), but apparently not this particular catalog.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 MAST: TESS, Kepler and K2\n",
    " - use lightKurve to search all 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on object 0 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (0.28136, -0.09789)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (0.28136, -0.09789)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 1 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (21.70037, -8.66335)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (21.70037, -8.66335)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 2 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (29.99, 0.55301)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (29.99, 0.55301)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 3 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (29.99015, 0.55288)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (29.99015, 0.55288)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 4 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (120.94815, 42.97747)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (120.94815, 42.97747)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 5 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (127.88438, 36.77146)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (127.88438, 36.77146)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 6 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (132.49077, 27.79139)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (132.49077, 27.79139)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 7 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (137.38346, 47.79186)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (137.38346, 47.79186)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 8 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (144.37635, 26.04226)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (144.37635, 26.04226)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 9 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (144.39777, 32.5472)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (144.39777, 32.5472)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 10 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (150.84777, 35.41774)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (150.84777, 35.41774)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 11 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (152.97077, 54.7018)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (152.97077, 54.7018)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 12 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (166.09674, 63.71816)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (166.09674, 63.71816)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 13 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (166.22989, 1.31573)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (166.22989, 1.31573)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 14 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (167.60602, -0.05948)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (167.60602, -0.05948)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 15 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (168.90238, 5.74715)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (168.90238, 5.74715)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 16 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (169.62351, 32.06666)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (169.62351, 32.06666)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 17 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (173.12142, 3.95808)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (173.12142, 3.95808)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 18 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (177.66385, 36.54956)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (177.66385, 36.54956)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 19 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (178.11465, 32.16646)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (178.11465, 32.16646)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 20 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (194.81978, 55.25199)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (194.81978, 55.25199)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 21 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (199.87808, 67.89872)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (199.87808, 67.89872)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 22 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (209.07707, -1.2539)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (209.07707, -1.2539)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 23 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (209.73263, 49.5706)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (209.73263, 49.5706)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 24 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (221.97599, 28.55669)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (221.97599, 28.55669)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 25 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (233.48331, 1.17494)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (233.48331, 1.17494)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 26 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (236.3735, 25.19107)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (236.3735, 25.19107)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 27 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (237.57179, 41.65064)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (237.57179, 41.65064)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 28 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (238.24292, 27.62456)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (238.24292, 27.62456)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 29 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (238.66774, 36.4978)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (238.66774, 36.4978)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working on object 30 <SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (354.01242, 0.29132)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data found for target \"<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (354.01242, 0.29132)>\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "radius = 1.0  #arcseconds\n",
    "\n",
    "#for all objects\n",
    "for count, coord in enumerate(coords_list):\n",
    "    print(\"working on object\", count, coord)\n",
    "    \n",
    "    #use lightkurve to search TESS, Kepler and K2\n",
    "    search_result = lk.search_lightcurve(coord, radius = radius)\n",
    "    \n",
    "    #figure out what to do with the results\n",
    "    if len(search_result) < 1:\n",
    "        #there is no data in these missions at this location\n",
    "    else:\n",
    "        #don't know what this looks like because none of these targets has a light curve\n",
    "        #https://docs.lightkurve.org/tutorials/1-getting-started/searching-for-data-products.html\n",
    "        #has a tutorial on how to do this\n",
    "        #might look something like this:\n",
    "        #lc_collection = search_result[*].download_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 MAST: HCV\n",
    " - hubble catalog of variables (https://archive.stsci.edu/hlsp/hcv)\n",
    " - follow notebook here to know how to search and download light curves https://archive.stsci.edu/hst/hsc/help/HCV/HCV_API_demo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find light curves for these targets in relevant, non-NASA catalogs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaia (Faisst)\n",
    "- astroquery.gaia will presumably work out of the box for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 \n",
      "Search completed in 79.36 seconds\n",
      "Number of objects mached: 28 out of 31.\n"
     ]
    }
   ],
   "source": [
    "############ EXTRACT GAIA DATA FOR OBJECTS ##########\n",
    "\n",
    "## Select Gaia table (DR3)\n",
    "Gaia.MAIN_GAIA_TABLE = \"gaiaedr3.gaia_source\"\n",
    "\n",
    "## Define search radius\n",
    "radius = u.Quantity(20, u.arcsec)\n",
    "\n",
    "## Search and Cross match.\n",
    "# This can be done in a smarter way by matching catalogs on the Gaia server, or grouping the\n",
    "# sources and search a larger area.\n",
    "\n",
    "# get catalog\n",
    "gaia_table = Table()\n",
    "t1 = time.time()\n",
    "for cc,coord in enumerate(coords_list):\n",
    "    print(len(coords_list)-cc , end=\" \")\n",
    "\n",
    "    gaia_search = Gaia.cone_search_async(coordinate=coord, radius=radius , background=True)\n",
    "    gaia_search.get_data()[\"dist\"].unit = \"deg\"\n",
    "    gaia_search.get_data()[\"dist\"] = gaia_search.get_data()[\"dist\"].to(u.arcsec) # Change distance unit from degrees to arcseconds\n",
    "    \n",
    "    \n",
    "    # match\n",
    "    if len(gaia_search.get_data()[\"dist\"]) > 0:\n",
    "        gaia_search.get_data()[\"input_object_name\"] = CLAGN[\"Object Name\"][cc] # add input object name to catalog\n",
    "        sel_min = np.where( (gaia_search.get_data()[\"dist\"] < 1*u.arcsec) & (gaia_search.get_data()[\"dist\"] == np.nanmin(gaia_search.get_data()[\"dist\"]) ) )[0]\n",
    "    else:\n",
    "        sel_min = []\n",
    "        \n",
    "    #print(\"Number of sources matched: {}\".format(len(sel_min)) )\n",
    "    \n",
    "    if len(sel_min) > 0:\n",
    "        gaia_table = vstack( [gaia_table , gaia_search.get_data()[sel_min]] )\n",
    "    else:\n",
    "        gaia_table = vstack( [gaia_table , gaia_search.get_data()[sel_min]] )\n",
    "\n",
    "print(\"\\nSearch completed in {:.2f} seconds\".format((time.time()-t1) ) )\n",
    "print(\"Number of objects mached: {} out of {}.\".format(len(gaia_table),len(CLAGN) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## EXTRACT PHOTOMETRY #########\n",
    "# Note that the fluxes are in e/s, not very useful. However, there are magnitudes (what unit??) but without errors.\n",
    "# We can get the errors from the flux errors?\n",
    "\n",
    "## Define keys (columns) that will be used later. Also add wavelength in angstroms for each filter\n",
    "mag_keys = [\"phot_bp_mean_mag\" , \"phot_g_mean_mag\" , \"phot_rp_mean_mag\"]\n",
    "magerr_keys = [\"phot_bp_mean_mag_error\" , \"phot_g_mean_mag_error\" , \"phot_rp_mean_mag_error\"]\n",
    "flux_keys = [\"phot_bp_mean_flux\" , \"phot_g_mean_flux\" , \"phot_rp_mean_flux\"]\n",
    "fluxerr_keys = [\"phot_bp_mean_flux_error\" , \"phot_g_mean_flux_error\" , \"phot_rp_mean_flux_error\"]\n",
    "mag_lambda = [\"5319.90\" , \"6735.42\" , \"7992.90\"]\n",
    "\n",
    "## Get photometry. Note that this includes only objects that are \n",
    "# matched to the catalog. We have to add the missing ones later.\n",
    "_phot = gaia_table[mag_keys]\n",
    "_err = hstack( [ 2.5/np.log(10) * gaia_table[e]/gaia_table[f] for e,f in zip(fluxerr_keys,flux_keys) ] )\n",
    "gaia_phot2 = hstack( [_phot , _err] )\n",
    "\n",
    "## Clean up (change units and column names)\n",
    "_ = [gaia_phot2.rename_column(f,m) for m,f in zip(magerr_keys,fluxerr_keys)]\n",
    "for key in magerr_keys:\n",
    "    gaia_phot2[key].unit = \"mag\"\n",
    "gaia_phot2[\"input_object_name\"] = gaia_table[\"input_object_name\"].copy()\n",
    "\n",
    "## Also add object for which we don't have photometry.\n",
    "# Add Nan for now, need to think about proper format. Also, there are probably smarter ways to do this.\n",
    "# We do this by matching the object names from the original catalog to the photometry catalog. Then add\n",
    "# an entry [np.nan, ...] if it does not exist. To make life easier, we add a dummy entry as the first\n",
    "# row so we can compy all the \n",
    "gaia_phot = Table( names=gaia_phot2.keys() , dtype=gaia_phot2.dtype )\n",
    "for ii in range(len(CLAGN)):\n",
    "    sel = np.where( CLAGN[\"Object Name\"][ii] == gaia_phot2[\"input_object_name\"] )[0]\n",
    "    if len(sel) > 0:\n",
    "        gaia_phot = vstack([gaia_phot , gaia_phot2[sel] ])\n",
    "    else:\n",
    "        tmp = Table( np.repeat(np.NaN , len(gaia_phot2.keys())) , names=gaia_phot2.keys() , dtype=gaia_phot2.dtype )\n",
    "        gaia_phot = vstack([gaia_phot , tmp ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phot_bp_mean_mag phot_g_mean_mag phot_rp_mean_mag phot_bp_mean_mag_error phot_g_mean_mag_error phot_rp_mean_mag_error     input_object_name    \n",
      "      mag              mag             mag                 mag                    mag                   mag                                    \n",
      "---------------- --------------- ---------------- ---------------------- --------------------- ---------------------- -------------------------\n",
      "             nan             nan              nan                    nan                   nan                    nan                       nan\n",
      "       19.334736       20.655428        18.006554     0.0489463475382072   0.01195253816419854    0.03560993262228968 WISEA J012648.10-083948.0\n",
      "       19.742887       20.841955         18.55511    0.09464535378467852   0.02097086422081428    0.04248351283430384   2MASS J01595763+0033105\n",
      "       19.742887       20.841955         18.55511    0.09464535378467852   0.02097086422081428    0.04248351283430384 WISEA J015957.63+003310.3\n",
      "             nan             nan              nan                    nan                   nan                    nan                       nan\n",
      "       18.682938       19.121965        17.443657    0.06859739379512571  0.021330523804058837    0.03162004672292963 WISEA J083132.25+364617.0\n",
      "       20.032625       20.557375        18.566603    0.06488202490701654  0.014519066831425122    0.04852070859643191 WISEA J084957.78+274728.8\n",
      "        18.83343       19.598389        17.521133    0.03458888778092869  0.016285677301456646    0.01904929130253408 WISEA J090932.02+474730.7\n",
      "       18.673218       19.429667        17.303476    0.03206049783838812   0.01638385902470684   0.015951683357388665 WISEA J093730.32+260232.1\n",
      "       20.719622       20.899273        20.309593    0.21206420971063977    0.0127293510325973    0.08330623112919122 WISEA J093735.45+323250.6\n",
      "       18.200468       18.499763         16.91392    0.03844232555379939   0.01714990678192904   0.026451385308381172 WISEA J100323.46+352503.8\n",
      "       19.619595       20.656897        18.403805    0.05453472749477915  0.012338307743282848   0.040835372481844184 WISEA J101152.99+544206.3\n",
      "       19.937426        21.00606        18.767895    0.07560871467243252  0.017358940646531835   0.029639224132883397 WISEA J110423.23+634305.2\n",
      "             nan             nan              nan                    nan                   nan                    nan                       nan\n",
      "       19.177925       19.460379        17.980103    0.06588865692512147  0.026474082800289827    0.03147298622848686 WISEA J111025.44-000334.1\n",
      "       18.464869       19.234829        17.152103    0.07593085210097976   0.03550375722728837    0.05933948408335441 WISEA J111536.56+054449.7\n",
      "       20.339615        20.92694        19.324455    0.22314439211453288  0.050885603619372055    0.11504180587462766 WISEA J111829.66+320400.0\n",
      "       18.131878       19.102892        16.809544   0.022033936427205306  0.015683407746881643   0.015797201278530137 WISEA J113229.14+035729.1\n",
      "       20.302738       21.031055         19.02412    0.11851525820756251  0.031049577608767722    0.09821581567984367 WISEA J115039.31+363258.3\n",
      "         20.1978       20.374107         18.47522     0.0865202827166565  0.006475987938930861    0.03329089887079503     FBQS J115227.5+320959\n",
      "       19.133806       19.522717        17.848743    0.04391213996920919   0.01722840080053144   0.030791177447689166 WISEA J125916.74+551507.1\n",
      "        18.36343       18.994835        17.185936   0.028814018342841197  0.014117377582083175   0.019365044097712805 WISEA J131930.75+675355.4\n",
      "       19.337309       19.772038        18.679356     0.0343266769847331  0.010097260520322109   0.029189919317396503 WISEA J135618.50-011514.0\n",
      "        19.23167       19.990995        18.109407    0.04067276857874131  0.012271122068066435   0.028570931164036632 WISEA J135855.82+493414.0\n",
      "       17.656807       18.011076        16.650372   0.024810326487981142   0.00986601220089287   0.014320332096800996 WISEA J144754.23+283324.1\n",
      "       18.879412       20.113039        17.437674   0.055547993309524764   0.01583562186684592   0.021049902715324503 WISEA J153355.99+011029.7\n",
      "       18.094048       19.134172        16.777948     0.0252111433628053  0.015455575156292103   0.017681559703418063 WISEA J154529.63+251127.9\n",
      "        18.89239       19.558643        17.498657    0.03719779255012713  0.014864182693170745   0.025478937985966617 WISEA J155017.23+413902.4\n",
      "       19.303299       19.721245        17.588148    0.04885142485011689  0.010884735268919523    0.02524641844934949 WISEA J155258.27+273728.5\n",
      "        18.53089       18.783075        17.495468   0.026886543515692477  0.008898602660410003    0.01792306879369694 WISEA J155440.26+362951.9\n",
      "       20.564999       21.272406        18.978415     0.3678877392428809  0.037285691524539914    0.20983582155857536 WISEA J233602.97+001728.9\n"
     ]
    }
   ],
   "source": [
    "gaia_phot.pprint_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASAS-SN (all sky automated survey for supernovae) has a website that can be manually searched (Faisst)\n",
    "- see if astroquery.vizier can find it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### icecube has a 2008 - 2018 catalog which we can download and is small (Faisst)\n",
    "- https://icecube.wisc.edu/data-releases/2021/01/all-sky-point-source-icecube-data-years-2008-2018/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make plots of luminosity as a function of time\n",
    "- time could be days since peak, or days since first observation, or??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image extension: look for archival images of these targets\n",
    "- NASA NAVO use cases should help us to learn how to do this\n",
    "- can use the cutout service now in astropy from the first fornax use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Extension \n",
    "Consider training a ML model to do light curve classification based on this sample of CLAGN\n",
    " - once we figure out which bands these are likely to be observed in, could then have a optical + IR light curve classifier\n",
    " - what would the features of the light curve be?\n",
    " - what models are reasonable to test as light curve classifiers?\n",
    " - could we make also a sample of TDEs, SNe, flaring AGN? - then train the model to distinguish between these things?\n",
    " - need a sample of non-flaring light curves\n",
    " \n",
    "After training the model:\n",
    " - would then need a sample of optical + IR light curves for \"all\" galaxies = big data to run the model on.\n",
    "\n",
    "Some resources to consider:\n",
    "- https://github.com/dirac-institute/ZTF_Boyajian\n",
    "- https://ui.adsabs.harvard.edu/abs/2022AJ....164...68S/abstract\n",
    "- https://ui.adsabs.harvard.edu/abs/2019ApJ...881L...9F/abstract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

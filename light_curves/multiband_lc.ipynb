{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiwavelength light curves using archival data\n",
    "\n",
    "### Summary:\n",
    " - model plots after van Velzen et al. 2021, https://arxiv.org/pdf/2111.09391.pdf\n",
    " \n",
    "### Input:\n",
    " - a catalog of CLAGN from the literature\n",
    "\n",
    "### Output:\n",
    " - an archival optical + IR + neutrino light curve\n",
    " \n",
    "### Technical Goals:\n",
    " - should be able to run from a clean checkout from github\n",
    " - should be able to automatically download all catalogs & images used\n",
    " - need to have all photometry in the same physical unit\n",
    " - need to have a data structure that is easy to use but holds light curve information (time and units) and is extendable to ML applications\n",
    " - need to have a curated list of catalogs to search for photometry that is generalizeable to other input catalogs\n",
    " \n",
    "### Authors:\n",
    "IPAC SP team\n",
    "\n",
    "### Acknowledgements:\n",
    "Suvi Gezari, Antara Basu-zych,\n",
    "MAST, HEASARC, & IRSA Fornax teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from astroquery.ipac.ned import Ned\n",
    "from astroquery.heasarc import Heasarc\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, vstack, hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following paper to make a sample of CLAGN: https://iopscience.iop.org/article/10.3847/1538-4357/aaca3a \n",
    "\n",
    "# This sample can later be switched out to a differen/larger sample of \"interesting\" targets\n",
    "\n",
    "#use ADS to find the refcode for this paper\n",
    "CLAGN = Ned.query_refcode('2018ApJ...862..109Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the best data structure for this work?\n",
    " - needs to hold multiwavelength light curves\n",
    " - understands both time and units on fluxes\n",
    " - would like to know if whatever we choose can be scaled up to make light curves of the while WISE sample\n",
    " - some things to look into\n",
    "     - astropy has a light curve class\n",
    "         -would probably need to do some development work to make this work for multiwavelength application\n",
    "     - LINCC people are interested in this and might have some suggestions on a 6mo. timescale\n",
    "     - xarray\n",
    "     - pandas might have more unit support now than before\n",
    "     - what is ZTF using?\n",
    "     - what did Dave do in his WISE parquet files?\n",
    "     \n",
    "- One suggestion is that instead of one large dataframe with the multiwavelength information, we keep them as seperate astropy light curves for each band, do the feature extraction on each light curve and keep the features in one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "astropy.table.table.Table"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(CLAGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build a list of skycoords from target ra and dec #####\n",
    "coords_list = [\n",
    "    SkyCoord(ra, dec, frame='icrs', unit='deg')\n",
    "    for ra, dec in zip(CLAGN['RA'], CLAGN['DEC'])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find photometry for these targets in NASA catalogs\n",
    "- look at NAVO use cases to get help with tools to do this - although they mostly use pyvo\n",
    "- deciding up front to use astroquery instead of pyvo\n",
    "    - astroquery is apparently more user friendly\n",
    "- data access concerns:\n",
    "    - can't ask the archives to search their entire holdings\n",
    "        - not good enough meta data\n",
    "        - not clear that the data is all vetted and good enough to include for science\n",
    "        - all catalogs have differently named columns so how would we know which columns to keep\n",
    "    - instead work with a curated list of catalogs for each archive\n",
    "        - focus on general surveys\n",
    "        - try to ensure that this list is also appropriate for a generalization of this use case to other input catalogs\n",
    "        - could astroquery.NED be useful in finding a generalized curated list\n",
    "- How do we know we have a match that is good enough to include in our light curve\n",
    "     - look at nway for the high energy catalogs\n",
    "     - probably need to generate a table of search radii for each catalog based on bandpass\n",
    "         - need domain knowledge for that\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEASARC (Krick)\n",
    "- asked Antara for help making a curated list of catalogs\n",
    "- Suvi mentioned scientifically sensible to include Fermi Gamma ray photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all the available HEASARC missions\n",
    "heasarc = Heasarc()\n",
    "mission_table = heasarc.query_mission_list()\n",
    "#mission_table.pprint_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out what the column names are in one of the catalogs\n",
    "cols = heasarc.query_mission_cols(mission='fermi3fgl')\n",
    "#cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all CLAGN coords in the paper\n",
    "c = 1 #just playing with astroquery query_region\n",
    "#do a query on position\n",
    "mission = 'fermi3fgl'\n",
    "radius = 0.1*u.degree\n",
    "results = heasarc.query_region(coords(c), mission = mission, radius = radius, sortvar = 'SEARCH_OFFSET_')\n",
    "#if there is a good match where good = ??\n",
    "#save the found photometry in the chosen data structure\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "astroquery.ipac.irsa \n",
    "\n",
    " - need to make a curated list of catalogs here\n",
    "     - ZTF (Faisst)\n",
    " \n",
    "     - WISE (Krick)\n",
    "         - use Dave Shupe's light curve catalog parquet file /irsa-data-download10/parquet-work/NEOWISE-R/neowise_lc_half.parquet\n",
    "         - can use existing code in https://github.com/IPAC-SW/ipac-sp-notebooks/blob/main/catwise_variables/nhel_xgboost.ipynb to access and work with this catalog\n",
    "         - will need to work on how to efficiently search that catalog since it is too big to fit in memory\n",
    "             - re-do work on Vaex and Dask and Spark\n",
    "         - Do we need updates to this catalog from Dave?\n",
    "             - once concern is that it is only half sky, hopefully enough of our targets are in the catalog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAST (Krick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- astroquery MAST doesn't require a catalog input but we might want it to narrow things down?\n",
    "    - which catalogs are interesting?\n",
    "        - Pan-STARRS\n",
    "        - need to ask someone at MAST for a curated list of catalogs to search\n",
    "        \n",
    "- MAST has copies of ATLAS all-sky stellar reference catalog- but not searchable\n",
    "     - might be available through astroquery.vizier\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find photometry for these targets in relevant, non-NASA catalogs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaia (Faisst)\n",
    "- astroquery.gaia will presumably work out of the box for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 \n",
      "Search completed in 76.60 seconds\n",
      "Number of objects mached: 28 out of 31.\n"
     ]
    }
   ],
   "source": [
    "############ EXTRACT GAIA DATA FOR OBJECTS ##########\n",
    "\n",
    "## Select Gaia table (DR3)\n",
    "Gaia.MAIN_GAIA_TABLE = \"gaiaedr3.gaia_source\"\n",
    "\n",
    "## Define search radius\n",
    "radius = u.Quantity(20, u.arcsec)\n",
    "\n",
    "## Search and Cross match.\n",
    "# This can be done in a smarter way by matching catalogs on the Gaia server, or grouping the\n",
    "# sources and search a larger area.\n",
    "\n",
    "# get catalog\n",
    "gaia_table = Table()\n",
    "t1 = time.time()\n",
    "for cc,coord in enumerate(coords_list):\n",
    "    print(len(coords_list)-cc , end=\" \")\n",
    "\n",
    "    gaia_search = Gaia.cone_search_async(coordinate=coord, radius=radius , background=True)\n",
    "    gaia_search.get_data()[\"dist\"].unit = \"deg\"\n",
    "    gaia_search.get_data()[\"dist\"] = gaia_search.get_data()[\"dist\"].to(u.arcsec) # Change distance unit from degrees to arcseconds\n",
    "    \n",
    "    \n",
    "    # match\n",
    "    if len(gaia_search.get_data()[\"dist\"]) > 0:\n",
    "        gaia_search.get_data()[\"input_object_name\"] = CLAGN[\"Object Name\"][cc] # add input object name to catalog\n",
    "        sel_min = np.where( (gaia_search.get_data()[\"dist\"] < 1*u.arcsec) & (gaia_search.get_data()[\"dist\"] == np.nanmin(gaia_search.get_data()[\"dist\"]) ) )[0]\n",
    "    else:\n",
    "        sel_min = []\n",
    "        \n",
    "    #print(\"Number of sources matched: {}\".format(len(sel_min)) )\n",
    "    \n",
    "    if len(sel_min) > 0:\n",
    "        gaia_table = vstack( [gaia_table , gaia_search.get_data()[sel_min]] )\n",
    "    else:\n",
    "        gaia_table = vstack( [gaia_table , gaia_search.get_data()[sel_min]] )\n",
    "\n",
    "print(\"\\nSearch completed in {:.2f} seconds\".format((time.time()-t1) ) )\n",
    "print(\"Number of objects mached: {} out of {}.\".format(len(gaia_table),len(CLAGN) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## EXTRACT PHOTOMETRY #########\n",
    "# Note that the fluxes are in e/s, not very useful. However, there are magnitudes (what unit??) but without errors.\n",
    "# We can get the errors from the flux errors?\n",
    "\n",
    "## Define keys (columns) that will be used later. Also add wavelength in angstroms for each filter\n",
    "mag_keys = [\"phot_bp_mean_mag\" , \"phot_g_mean_mag\" , \"phot_rp_mean_mag\"]\n",
    "magerr_keys = [\"phot_bp_mean_mag_error\" , \"phot_g_mean_mag_error\" , \"phot_rp_mean_mag_error\"]\n",
    "flux_keys = [\"phot_bp_mean_flux\" , \"phot_g_mean_flux\" , \"phot_rp_mean_flux\"]\n",
    "fluxerr_keys = [\"phot_bp_mean_flux_error\" , \"phot_g_mean_flux_error\" , \"phot_rp_mean_flux_error\"]\n",
    "mag_lambda = [\"5319.90\" , \"6735.42\" , \"7992.90\"]\n",
    "\n",
    "## Get photometry. Note that this includes only objects that are \n",
    "# matched to the catalog. We have to add the missing ones later.\n",
    "_phot = gaia_table[mag_keys]\n",
    "_err = hstack( [ 2.5/np.log(10) * gaia_table[e]/gaia_table[f] for e,f in zip(fluxerr_keys,flux_keys) ] )\n",
    "gaia_phot2 = hstack( [_phot , _err] )\n",
    "\n",
    "## Clean up (change units and column names)\n",
    "_ = [gaia_phot2.rename_column(f,m) for m,f in zip(magerr_keys,fluxerr_keys)]\n",
    "for key in magerr_keys:\n",
    "    gaia_phot2[key].unit = \"mag\"\n",
    "gaia_phot2[\"input_object_name\"] = gaia_table[\"input_object_name\"].copy()\n",
    "\n",
    "## Also add object for which we don't have photometry.\n",
    "# Add Nan for now, need to think about proper format. Also, there are probably smarter ways to do this.\n",
    "# We do this by matching the object names from the original catalog to the photometry catalog. Then add\n",
    "# an entry [np.nan, ...] if it does not exist. To make life easier, we add a dummy entry as the first\n",
    "# row so we can compy all the \n",
    "gaia_phot = Table( names=gaia_phot2.keys() , dtype=gaia_phot2.dtype )\n",
    "for ii in range(len(CLAGN)):\n",
    "    sel = np.where( CLAGN[\"Object Name\"][ii] == gaia_phot2[\"input_object_name\"] )[0]\n",
    "    if len(sel) > 0:\n",
    "        gaia_phot = vstack([gaia_phot , gaia_phot2[sel] ])\n",
    "    else:\n",
    "        tmp = Table( np.repeat(np.NaN , len(gaia_phot2.keys())) , names=gaia_phot2.keys() , dtype=gaia_phot2.dtype )\n",
    "        gaia_phot = vstack([gaia_phot , tmp ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=31</i>\n",
       "<table id=\"table140651083943600\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>phot_bp_mean_mag</th><th>phot_g_mean_mag</th><th>phot_rp_mean_mag</th><th>phot_bp_mean_mag_error</th><th>phot_g_mean_mag_error</th><th>phot_rp_mean_mag_error</th><th>input_object_name</th></tr></thead>\n",
       "<thead><tr><th>mag</th><th>mag</th><th>mag</th><th>mag</th><th>mag</th><th>mag</th><th></th></tr></thead>\n",
       "<thead><tr><th>float32</th><th>float32</th><th>float32</th><th>float64</th><th>float64</th><th>float64</th><th>str25</th></tr></thead>\n",
       "<tr><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>19.334736</td><td>20.655428</td><td>18.006554</td><td>0.0489463475382072</td><td>0.01195253816419854</td><td>0.03560993262228968</td><td>WISEA J012648.10-083948.0</td></tr>\n",
       "<tr><td>19.742887</td><td>20.841955</td><td>18.55511</td><td>0.09464535378467852</td><td>0.02097086422081428</td><td>0.04248351283430384</td><td>2MASS J01595763+0033105</td></tr>\n",
       "<tr><td>19.742887</td><td>20.841955</td><td>18.55511</td><td>0.09464535378467852</td><td>0.02097086422081428</td><td>0.04248351283430384</td><td>WISEA J015957.63+003310.3</td></tr>\n",
       "<tr><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>18.682938</td><td>19.121965</td><td>17.443657</td><td>0.06859739379512571</td><td>0.021330523804058837</td><td>0.03162004672292963</td><td>WISEA J083132.25+364617.0</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>18.879412</td><td>20.113039</td><td>17.437674</td><td>0.055547993309524764</td><td>0.01583562186684592</td><td>0.021049902715324503</td><td>WISEA J153355.99+011029.7</td></tr>\n",
       "<tr><td>18.094048</td><td>19.134172</td><td>16.777948</td><td>0.0252111433628053</td><td>0.015455575156292103</td><td>0.017681559703418063</td><td>WISEA J154529.63+251127.9</td></tr>\n",
       "<tr><td>18.89239</td><td>19.558643</td><td>17.498657</td><td>0.03719779255012713</td><td>0.014864182693170745</td><td>0.025478937985966617</td><td>WISEA J155017.23+413902.4</td></tr>\n",
       "<tr><td>19.303299</td><td>19.721245</td><td>17.588148</td><td>0.04885142485011689</td><td>0.010884735268919523</td><td>0.02524641844934949</td><td>WISEA J155258.27+273728.5</td></tr>\n",
       "<tr><td>18.53089</td><td>18.783075</td><td>17.495468</td><td>0.026886543515692477</td><td>0.008898602660410003</td><td>0.01792306879369694</td><td>WISEA J155440.26+362951.9</td></tr>\n",
       "<tr><td>20.564999</td><td>21.272406</td><td>18.978415</td><td>0.3678877392428809</td><td>0.037285691524539914</td><td>0.20983582155857536</td><td>WISEA J233602.97+001728.9</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=31>\n",
       "phot_bp_mean_mag phot_g_mean_mag ...     input_object_name    \n",
       "      mag              mag       ...                          \n",
       "    float32          float32     ...           str25          \n",
       "---------------- --------------- ... -------------------------\n",
       "             nan             nan ...                       nan\n",
       "       19.334736       20.655428 ... WISEA J012648.10-083948.0\n",
       "       19.742887       20.841955 ...   2MASS J01595763+0033105\n",
       "       19.742887       20.841955 ... WISEA J015957.63+003310.3\n",
       "             nan             nan ...                       nan\n",
       "       18.682938       19.121965 ... WISEA J083132.25+364617.0\n",
       "             ...             ... ...                       ...\n",
       "       18.879412       20.113039 ... WISEA J153355.99+011029.7\n",
       "       18.094048       19.134172 ... WISEA J154529.63+251127.9\n",
       "        18.89239       19.558643 ... WISEA J155017.23+413902.4\n",
       "       19.303299       19.721245 ... WISEA J155258.27+273728.5\n",
       "        18.53089       18.783075 ... WISEA J155440.26+362951.9\n",
       "       20.564999       21.272406 ... WISEA J233602.97+001728.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaia_phot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASAS-SN (all sky automated survey for supernovae) has a website that can be manually searched (Faisst)\n",
    "- see if astroquery.vizier can find it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### icecube has a 2008 - 2018 catalog which we can download and is small (Faisst)\n",
    "- https://icecube.wisc.edu/data-releases/2021/01/all-sky-point-source-icecube-data-years-2008-2018/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make plots of luminosity as a function of time\n",
    "- time could be days since peak, or days since first observation, or??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image extension: look for archival images of these targets\n",
    "- NASA NAVO use cases should help us to learn how to do this\n",
    "- can use the cutout service now in astropy from the first fornax use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Extension \n",
    "Consider training a ML model to do light curve classification based on this sample of CLAGN\n",
    " - once we figure out which bands these are likely to be observed in, could then have a optical + IR light curve classifier\n",
    " - what would the features of the light curve be?\n",
    " - what models are reasonable to test as light curve classifiers?\n",
    " - could we make also a sample of TDEs, SNe, flaring AGN? - then train the model to distinguish between these things?\n",
    " - need a sample of non-flaring light curves\n",
    " \n",
    "After training the model:\n",
    " - would then need a sample of optical + IR light curves for \"all\" galaxies = big data to run the model on.\n",
    "\n",
    "Some resources to consider:\n",
    "- https://github.com/dirac-institute/ZTF_Boyajian\n",
    "- https://ui.adsabs.harvard.edu/abs/2022AJ....164...68S/abstract\n",
    "- https://ui.adsabs.harvard.edu/abs/2019ApJ...881L...9F/abstract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
